{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install segmentation_models","metadata":{"id":"HRJUKjN1QXgS","execution":{"iopub.status.busy":"2023-04-15T08:41:22.084555Z","iopub.execute_input":"2023-04-15T08:41:22.084985Z","iopub.status.idle":"2023-04-15T08:41:33.667835Z","shell.execute_reply.started":"2023-04-15T08:41:22.084875Z","shell.execute_reply":"2023-04-15T08:41:33.666430Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting segmentation_models\n  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\nCollecting image-classifiers==1.0.0\n  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\nCollecting efficientnet==1.0.0\n  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\nCollecting keras-applications<=1.0.8,>=1.0.7\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n     |████████████████████████████████| 50 kB 4.6 MB/s             \n\u001b[?25hRequirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.0.0->segmentation_models) (0.19.1)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.20.3)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (3.1.0)\nRequirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.5.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (21.3)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2021.11.2)\nRequirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (8.2.0)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.7.3)\nRequirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.6.3)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.2.0)\nRequirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->scikit-image->efficientnet==1.0.0->segmentation_models) (3.0.6)\nInstalling collected packages: keras-applications, image-classifiers, efficientnet, segmentation-models\nSuccessfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nimport segmentation_models as sm\nimport glob\nimport cv2\nimport os\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport keras \nfrom sklearn.model_selection import train_test_split","metadata":{"id":"bGIcq3_DQXgT","execution":{"iopub.status.busy":"2023-04-15T08:41:33.669951Z","iopub.execute_input":"2023-04-15T08:41:33.670262Z","iopub.status.idle":"2023-04-15T08:41:42.026908Z","shell.execute_reply.started":"2023-04-15T08:41:33.670222Z","shell.execute_reply":"2023-04-15T08:41:42.025604Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Segmentation Models: using `keras` framework.\n","output_type":"stream"}]},{"cell_type":"code","source":"os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\nsm.set_framework('tf.keras')\nkeras.backend.set_image_data_format('channels_last')","metadata":{"id":"x2HKIVofm8y7","execution":{"iopub.status.busy":"2023-04-15T08:41:42.028668Z","iopub.execute_input":"2023-04-15T08:41:42.028982Z","iopub.status.idle":"2023-04-15T08:41:42.436219Z","shell.execute_reply.started":"2023-04-15T08:41:42.028941Z","shell.execute_reply":"2023-04-15T08:41:42.435387Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing Pipeline","metadata":{"id":"OdS9NTtwQXgV"}},{"cell_type":"code","source":"H = 256 # height of image\nW = 256 # width of image\n\n'''This function is used to return the list of path for images and masks in\nsorted order from the given directory respectively.'''\n# function to return list of image paths and mask paths \ndef process_data(IMG_DIR, MASK_DIR):\n    images = [os.path.join(IMG_DIR, x) for x in sorted(os.listdir(IMG_DIR))]\n    masks = [os.path.join(MASK_DIR, x) for x in sorted(os.listdir(MASK_DIR))]\n\n    return images, masks\n\n'''This function is used to return splitted list of images and corresponding \nmask paths in train and test by providing test size.'''\n# function to load data and train test split\ndef load_data(IMG_DIR, MASK_DIR):\n    X, y = process_data(IMG_DIR, MASK_DIR)\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42)\n    \n    return X_train, X_test, y_train, y_test\n\n'''This function is used to read images. It takes image path as input. \nAfter reading image it is resized by width and height provide above(256 x 256). \nNext normalization is done by dividing each values with 255. And the result is returned.'''\n# function to read image\ndef read_image(x):\n    x = cv2.imread(x, cv2.IMREAD_COLOR)\n    x = cv2.resize(x, (W, H))\n    x = x / 255.0\n    x = x.astype(np.float32)\n    return x\n\n'''This function is used to read masks.'''\n# function to read mask\ndef read_mask(x):\n    x = cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n    x = cv2.resize(x, (W, H))\n    x = x.astype(np.int32)\n    return x\n\n'''This function is used to generate tensorflow data pipeline. \nThe tensorflow data pipeline is mapped to function ‘preprocess’ .'''\n# function for tensorflow dataset pipeline\ndef tf_dataset(x, y, batch=8):\n    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n    dataset = dataset.shuffle(buffer_size=5000)\n    dataset = dataset.map(preprocess)\n    dataset = dataset.batch(batch)\n    dataset = dataset.repeat()\n    dataset = dataset.prefetch(2)\n    return dataset\n\n'''This function takes image and mask path. \nIt reads the image and mask as provided by paths. \nMask is one hot encoded for multi class segmentation (here 4 class).'''\n# function to read image and mask amd create one hot encoding for mask\ndef preprocess(x, y):\n    def f(x, y):\n        x = x.decode()\n        y = y.decode()\n\n        image = read_image(x)\n        mask = read_mask(y)\n\n        return image, mask\n\n    image, mask = tf.numpy_function(f, [x, y], [tf.float32, tf.int32])\n    mask = tf.one_hot(mask, 4, dtype=tf.int32)\n    image.set_shape([H, W, 3])\n    mask.set_shape([H, W, 4])\n\n    return image, mask","metadata":{"id":"EQGsLbOVQXgW","execution":{"iopub.status.busy":"2023-04-15T08:41:42.439712Z","iopub.execute_input":"2023-04-15T08:41:42.440749Z","iopub.status.idle":"2023-04-15T08:41:42.456848Z","shell.execute_reply.started":"2023-04-15T08:41:42.440702Z","shell.execute_reply":"2023-04-15T08:41:42.455653Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Load the dataset","metadata":{"id":"ufOlyg7MQXgY"}},{"cell_type":"code","source":"'''RENDER_IMAGE_DIR_PATH: ‘Path of image directory’\nGROUND_MASK_DIR_PATH: ‘Path of mask directory’\n\nHere load_data function is called. This will load the dataset paths and \nsplit it into X_train, X_test, y_train, y_test '''\n\nRENDER_IMAGE_DIR_PATH = '../input/artificial-lunar-rocky-landscape-dataset/images/render'\nGROUND_MASK_DIR_PATH = '../input/artificial-lunar-rocky-landscape-dataset/images/clean'\n\nX_train, X_test, y_train, y_test = load_data(RENDER_IMAGE_DIR_PATH, GROUND_MASK_DIR_PATH)\nprint(f\"Dataset:\\n Train: {len(X_train)} \\n Test: {len(X_test)}\")","metadata":{"id":"vHWstFNTQXgY","execution":{"iopub.status.busy":"2023-04-15T08:41:42.458504Z","iopub.execute_input":"2023-04-15T08:41:42.458757Z","iopub.status.idle":"2023-04-15T08:41:43.988662Z","shell.execute_reply.started":"2023-04-15T08:41:42.458726Z","shell.execute_reply":"2023-04-15T08:41:43.987603Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Dataset:\n Train: 7812 \n Test: 1954\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Generate tensorflow data pipeline","metadata":{"id":"WfSTVsjCQXgZ"}},{"cell_type":"code","source":"batch_size = 8\n\n'''Here the tf_dataset function is called will generate the tensorflow data pipeline.'''\n# calling tf_dataset\ntrain_dataset = tf_dataset(X_train, y_train, batch=batch_size)\nvalid_dataset = tf_dataset(X_test, y_test, batch=batch_size)","metadata":{"id":"4xsJKtW0QXgZ","execution":{"iopub.status.busy":"2023-04-15T08:41:43.990034Z","iopub.execute_input":"2023-04-15T08:41:43.990280Z","iopub.status.idle":"2023-04-15T08:41:44.286914Z","shell.execute_reply.started":"2023-04-15T08:41:43.990238Z","shell.execute_reply":"2023-04-15T08:41:44.285806Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Creating U-net Architecture","metadata":{"id":"1MqxtDTmQXga"}},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, UpSampling2D, Concatenate\nfrom tensorflow.keras.models import Model\n\n'''conv_block it is used to create one block with two convolution layer \nfollowed by BatchNormalization and activation function relu. \nIf the pooling is required then Maxpool2D is applied and return it else not.'''\n# function to create convolution block\ndef conv_block(inputs, filters, pool=True):\n    x = Conv2D(filters, 3, padding=\"same\")(inputs)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    x = Conv2D(filters, 3, padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    if pool == True:\n        p = MaxPool2D((2, 2))(x)\n        return x, p\n    else:\n        return x\n\n'''build_unet it is used to create the U-net architecture.'''\n# function to build U-net\ndef build_unet(shape, num_classes):\n    inputs = Input(shape)\n\n    \"\"\" Encoder \"\"\"\n    x1, p1 = conv_block(inputs, 16, pool=True)\n    x2, p2 = conv_block(p1, 32, pool=True)\n    x3, p3 = conv_block(p2, 48, pool=True)\n    x4, p4 = conv_block(p3, 64, pool=True)\n\n    \"\"\" Bridge \"\"\"\n    b1 = conv_block(p4, 128, pool=False)\n\n    \"\"\" Decoder \"\"\"\n    u1 = UpSampling2D((2, 2), interpolation=\"bilinear\")(b1)\n    c1 = Concatenate()([u1, x4])\n    x5 = conv_block(c1, 64, pool=False)\n\n    u2 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x5)\n    c2 = Concatenate()([u2, x3])\n    x6 = conv_block(c2, 48, pool=False)\n\n    u3 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x6)\n    c3 = Concatenate()([u3, x2])\n    x7 = conv_block(c3, 32, pool=False)\n\n    u4 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x7)\n    c4 = Concatenate()([u4, x1])\n    x8 = conv_block(c4, 16, pool=False)\n\n    \"\"\" Output layer \"\"\"\n    output = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(x8)\n\n    return Model(inputs, output)","metadata":{"id":"tYCyf8smQXga","execution":{"iopub.status.busy":"2023-04-15T08:41:44.288496Z","iopub.execute_input":"2023-04-15T08:41:44.288805Z","iopub.status.idle":"2023-04-15T08:41:44.306570Z","shell.execute_reply.started":"2023-04-15T08:41:44.288763Z","shell.execute_reply":"2023-04-15T08:41:44.305357Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# calling build_unet function\nmodel = build_unet((256, 256, 3), 4)\nmodel.summary()","metadata":{"id":"65hPnreJQXgb","execution":{"iopub.status.busy":"2023-04-15T08:41:44.308366Z","iopub.execute_input":"2023-04-15T08:41:44.309394Z","iopub.status.idle":"2023-04-15T08:41:44.839090Z","shell.execute_reply.started":"2023-04-15T08:41:44.309343Z","shell.execute_reply":"2023-04-15T08:41:44.838036Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 256, 256, 16) 448         input_1[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 256, 256, 16) 64          conv2d[0][0]                     \n__________________________________________________________________________________________________\nactivation (Activation)         (None, 256, 256, 16) 0           batch_normalization[0][0]        \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 256, 256, 16) 2320        activation[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 256, 256, 16) 64          conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 256, 256, 16) 0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nmax_pooling2d (MaxPooling2D)    (None, 128, 128, 16) 0           activation_1[0][0]               \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 128, 128, 32) 4640        max_pooling2d[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 128, 128, 32) 128         conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, 128, 128, 32) 0           batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 128, 128, 32) 9248        activation_2[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 128, 128, 32) 128         conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nactivation_3 (Activation)       (None, 128, 128, 32) 0           batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nmax_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 32)   0           activation_3[0][0]               \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 64, 64, 48)   13872       max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 64, 64, 48)   192         conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 64, 64, 48)   0           batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 64, 64, 48)   20784       activation_4[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_5 (BatchNor (None, 64, 64, 48)   192         conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nactivation_5 (Activation)       (None, 64, 64, 48)   0           batch_normalization_5[0][0]      \n__________________________________________________________________________________________________\nmax_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 48)   0           activation_5[0][0]               \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 32, 32, 64)   27712       max_pooling2d_2[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_6 (BatchNor (None, 32, 32, 64)   256         conv2d_6[0][0]                   \n__________________________________________________________________________________________________\nactivation_6 (Activation)       (None, 32, 32, 64)   0           batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 32, 32, 64)   36928       activation_6[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_7 (BatchNor (None, 32, 32, 64)   256         conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nactivation_7 (Activation)       (None, 32, 32, 64)   0           batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\nmax_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 64)   0           activation_7[0][0]               \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 16, 16, 128)  73856       max_pooling2d_3[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_8 (BatchNor (None, 16, 16, 128)  512         conv2d_8[0][0]                   \n__________________________________________________________________________________________________\nactivation_8 (Activation)       (None, 16, 16, 128)  0           batch_normalization_8[0][0]      \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 16, 16, 128)  147584      activation_8[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_9 (BatchNor (None, 16, 16, 128)  512         conv2d_9[0][0]                   \n__________________________________________________________________________________________________\nactivation_9 (Activation)       (None, 16, 16, 128)  0           batch_normalization_9[0][0]      \n__________________________________________________________________________________________________\nup_sampling2d (UpSampling2D)    (None, 32, 32, 128)  0           activation_9[0][0]               \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 32, 32, 192)  0           up_sampling2d[0][0]              \n                                                                 activation_7[0][0]               \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 32, 32, 64)   110656      concatenate[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_10 (BatchNo (None, 32, 32, 64)   256         conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nactivation_10 (Activation)      (None, 32, 32, 64)   0           batch_normalization_10[0][0]     \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 32, 32, 64)   36928       activation_10[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_11 (BatchNo (None, 32, 32, 64)   256         conv2d_11[0][0]                  \n__________________________________________________________________________________________________\nactivation_11 (Activation)      (None, 32, 32, 64)   0           batch_normalization_11[0][0]     \n__________________________________________________________________________________________________\nup_sampling2d_1 (UpSampling2D)  (None, 64, 64, 64)   0           activation_11[0][0]              \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 64, 64, 112)  0           up_sampling2d_1[0][0]            \n                                                                 activation_5[0][0]               \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 64, 64, 48)   48432       concatenate_1[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_12 (BatchNo (None, 64, 64, 48)   192         conv2d_12[0][0]                  \n__________________________________________________________________________________________________\nactivation_12 (Activation)      (None, 64, 64, 48)   0           batch_normalization_12[0][0]     \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 64, 64, 48)   20784       activation_12[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_13 (BatchNo (None, 64, 64, 48)   192         conv2d_13[0][0]                  \n__________________________________________________________________________________________________\nactivation_13 (Activation)      (None, 64, 64, 48)   0           batch_normalization_13[0][0]     \n__________________________________________________________________________________________________\nup_sampling2d_2 (UpSampling2D)  (None, 128, 128, 48) 0           activation_13[0][0]              \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 128, 128, 80) 0           up_sampling2d_2[0][0]            \n                                                                 activation_3[0][0]               \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 128, 128, 32) 23072       concatenate_2[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_14 (BatchNo (None, 128, 128, 32) 128         conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nactivation_14 (Activation)      (None, 128, 128, 32) 0           batch_normalization_14[0][0]     \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 128, 128, 32) 9248        activation_14[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_15 (BatchNo (None, 128, 128, 32) 128         conv2d_15[0][0]                  \n__________________________________________________________________________________________________\nactivation_15 (Activation)      (None, 128, 128, 32) 0           batch_normalization_15[0][0]     \n__________________________________________________________________________________________________\nup_sampling2d_3 (UpSampling2D)  (None, 256, 256, 32) 0           activation_15[0][0]              \n__________________________________________________________________________________________________\nconcatenate_3 (Concatenate)     (None, 256, 256, 48) 0           up_sampling2d_3[0][0]            \n                                                                 activation_1[0][0]               \n__________________________________________________________________________________________________\nconv2d_16 (Conv2D)              (None, 256, 256, 16) 6928        concatenate_3[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_16 (BatchNo (None, 256, 256, 16) 64          conv2d_16[0][0]                  \n__________________________________________________________________________________________________\nactivation_16 (Activation)      (None, 256, 256, 16) 0           batch_normalization_16[0][0]     \n__________________________________________________________________________________________________\nconv2d_17 (Conv2D)              (None, 256, 256, 16) 2320        activation_16[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_17 (BatchNo (None, 256, 256, 16) 64          conv2d_17[0][0]                  \n__________________________________________________________________________________________________\nactivation_17 (Activation)      (None, 256, 256, 16) 0           batch_normalization_17[0][0]     \n__________________________________________________________________________________________________\nconv2d_18 (Conv2D)              (None, 256, 256, 4)  68          activation_17[0][0]              \n==================================================================================================\nTotal params: 599,412\nTrainable params: 597,620\nNon-trainable params: 1,792\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load model and compile","metadata":{"id":"bMgeqmX2QXgc"}},{"cell_type":"code","source":"# importing libraries\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\nfrom segmentation_models.metrics import iou_score\nimport datetime, os\n\n\"\"\" Hyperparameters \"\"\"\nimg_shape = (256, 256, 3)\nnum_classes = 4\nlr = 1e-4\nbatch_size = 16\nepochs = 5\n\n\"\"\" Model \"\"\"\nmodel = build_unet(img_shape, num_classes)\nmodel.compile(loss=\"categorical_crossentropy\", \n              optimizer=tf.keras.optimizers.Adam(lr), \n              metrics=[iou_score])\n\n\ntrain_steps = len(X_train)//batch_size\nvalid_steps = len(X_test)//batch_size","metadata":{"id":"z91qV2ZwQXgc","execution":{"iopub.status.busy":"2023-04-15T08:41:44.840675Z","iopub.execute_input":"2023-04-15T08:41:44.840911Z","iopub.status.idle":"2023-04-15T08:41:45.261779Z","shell.execute_reply.started":"2023-04-15T08:41:44.840882Z","shell.execute_reply":"2023-04-15T08:41:45.260685Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Train model","metadata":{"id":"SBhRPBKPQXgc"}},{"cell_type":"code","source":"'''model.fit is used to train the model'''\nmodel_history = model.fit(train_dataset,\n        steps_per_epoch=train_steps,\n        validation_data=valid_dataset,\n        validation_steps=valid_steps,\n        epochs=epochs,\n    )","metadata":{"id":"4lJgBNVwQXgd","execution":{"iopub.status.busy":"2023-04-15T08:41:45.263946Z","iopub.execute_input":"2023-04-15T08:41:45.264189Z","iopub.status.idle":"2023-04-15T09:58:10.674650Z","shell.execute_reply.started":"2023-04-15T08:41:45.264160Z","shell.execute_reply":"2023-04-15T09:58:10.673570Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/5\n488/488 [==============================] - 937s 2s/step - loss: 0.4114 - iou_score: 0.1436 - val_loss: 0.2682 - val_iou_score: 0.1463\nEpoch 2/5\n488/488 [==============================] - 911s 2s/step - loss: 0.2316 - iou_score: 0.1751 - val_loss: 0.2233 - val_iou_score: 0.1791\nEpoch 3/5\n488/488 [==============================] - 907s 2s/step - loss: 0.1820 - iou_score: 0.1830 - val_loss: 0.1693 - val_iou_score: 0.1825\nEpoch 4/5\n488/488 [==============================] - 914s 2s/step - loss: 0.1412 - iou_score: 0.1888 - val_loss: 0.1063 - val_iou_score: 0.1974\nEpoch 5/5\n488/488 [==============================] - 916s 2s/step - loss: 0.0999 - iou_score: 0.2001 - val_loss: 0.1013 - val_iou_score: 0.2021\n","output_type":"stream"}]}]}